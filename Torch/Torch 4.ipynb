{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWo8E+whn2XDSszJ0ttfwn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ta4vDHPiK6QH"},"outputs":[],"source":["import torch\n","import random\n","import copy\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_wine"]},{"cell_type":"code","source":["wine = load_wine()\n","features =  13 # all features from dataset\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    wine.data[:, :features], \n","    wine.target, \n","    test_size=0.3,\n","    shuffle=True)\n","\n","X_train = torch.FloatTensor(X_train)\n","X_test = torch.FloatTensor(X_test)\n","y_train = torch.LongTensor(y_train)\n","y_test = torch.LongTensor(y_test)"],"metadata":{"id":"inqJ1c1vK9J5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class WineNet(torch.nn.Module):\n","    def __init__(self, n_input, n_hidden_neurons):\n","        super(WineNet, self).__init__()\n","        self.fc1 = torch.nn.Linear(n_input, n_hidden_neurons)\n","        self.activ1 = torch.nn.Sigmoid()\n","        self.fc2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n","        self.activ2 = torch.nn.Tanh()\n","        self.fc3 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n","        self.sm = torch.nn.Softmax(dim=1)\n","        \n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.activ1(x)\n","        x = self.fc2(x)\n","        x = self.activ2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","    def inference(self, x):\n","        x = self.forward(x)\n","        x = self.sm(x)\n","        return x"],"metadata":{"id":"ZsT7GUjFLBt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_input =  13 # all features\n","n_hidden =  50\n","wine_net = WineNet(n_input, n_hidden)"],"metadata":{"id":"04OW_0H1PPzS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(wine_net.parameters(), lr=1.0e-3)"],"metadata":{"id":"2zOigJjULEMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_wine_net = None\n","best_net_result = 0"],"metadata":{"id":"VKEB0onVStnc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size =  10 # choose different batch sizes\n","\n","for epoch in range(2000):\n","    order = np.random.permutation(len(X_train))\n","    for start_index in range(0, len(X_train), batch_size):\n","        optimizer.zero_grad()\n","        \n","        batch_indexes = order[start_index:start_index + batch_size]\n","        \n","        x_batch = X_train[batch_indexes]\n","        y_batch = y_train[batch_indexes]\n","        \n","        preds = wine_net.forward(x_batch)\n","        \n","        loss_value = loss(preds, y_batch)\n","        loss_value.backward()\n","        \n","        optimizer.step()\n","        \n","    if epoch % 20 == 0:\n","        test_preds = wine_net.forward(X_test)\n","        test_preds = test_preds.argmax(dim=1)\n","        accuracy = (test_preds == y_test).float().mean()\n","        if accuracy >= best_net_result:\n","            print(accuracy)\n","            best_net_result = accuracy\n","            best_wine_net = copy.deepcopy(wine_net)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsobUkiqLIRQ","executionInfo":{"status":"ok","timestamp":1678901617785,"user_tz":-180,"elapsed":32565,"user":{"displayName":"Матвей Званцов","userId":"01712077817502948720"}},"outputId":"5dbb2355-35a2-48e1-f71c-ce8e8e43877d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.3704)\n","tensor(0.6296)\n","tensor(0.7778)\n","tensor(0.8333)\n","tensor(0.8519)\n","tensor(0.8704)\n","tensor(0.8889)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9074)\n","tensor(0.9259)\n"]}]},{"cell_type":"code","source":["test_preds = best_wine_net.forward(X_test)\n","test_preds = test_preds.argmax(dim=1)\n","print((test_preds == y_test).float().mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeGVPmDaRLpM","executionInfo":{"status":"ok","timestamp":1678901670362,"user_tz":-180,"elapsed":9,"user":{"displayName":"Матвей Званцов","userId":"01712077817502948720"}},"outputId":"6960edca-8635-418a-faf2-5d43aec16e60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.9259)\n"]}]},{"cell_type":"code","source":["print(best_wine_net.fc1.in_features, np.asarray((test_preds == y_test).float().mean()) > 0.8)\n","# need to get 13 True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzMQR0LmLLfB","executionInfo":{"status":"ok","timestamp":1678901672301,"user_tz":-180,"elapsed":6,"user":{"displayName":"Матвей Званцов","userId":"01712077817502948720"}},"outputId":"88cc65e0-c9be-4878-ea7a-44fe47db7611"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["13 True\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Создаем входной массив из двух изображений RGB 3*3\n","input_images = torch.tensor(\n","      [[[[0,  1,  2],\n","         [3,  4,  5],\n","         [6,  7,  8]],\n","\n","        [[9, 10, 11],\n","         [12, 13, 14],\n","         [15, 16, 17]],\n","\n","        [[18, 19, 20],\n","         [21, 22, 23],\n","         [24, 25, 26]]],\n","\n","\n","       [[[27, 28, 29],\n","         [30, 31, 32],\n","         [33, 34, 35]],\n","\n","        [[36, 37, 38],\n","         [39, 40, 41],\n","         [42, 43, 44]],\n","\n","        [[45, 46, 47],\n","         [48, 49, 50],\n","         [51, 52, 53]]]])\n","\n","\n","def get_padding2d(input_images):\n","    padded_images = [] # добавить нулей с четырех сторон каждого изображения\n","    for image_num in range(input_images.shape[3]):\n","        padded_images.append([])\n","        for depth in range(input_images.shape[2]):\n","            padded_images[image_num].append([])\n","            padded_images[image_num][depth].append([0] * (input_images.shape[1] + 2))\n","            for row in input_images[:, :, depth, image_num]:\n","                padded_images[image_num][depth].append([0] + list(row) + [0])\n","            padded_images[image_num].append([0] * (input_images.shape[1] + 2))\n","    return torch.Tensor(padded_images)\n","\n","\n","correct_padded_images = torch.tensor(\n","       [[[[0.,  0.,  0.,  0.,  0.],\n","          [0.,  0.,  1.,  2.,  0.],\n","          [0.,  3.,  4.,  5.,  0.],\n","          [0.,  6.,  7.,  8.,  0.],\n","          [0.,  0.,  0.,  0.,  0.]],\n","\n","         [[0.,  0.,  0.,  0.,  0.],\n","          [0.,  9., 10., 11.,  0.],\n","          [0., 12., 13., 14.,  0.],\n","          [0., 15., 16., 17.,  0.],\n","          [0.,  0.,  0.,  0.,  0.]],\n","\n","         [[0.,  0.,  0.,  0.,  0.],\n","          [0., 18., 19., 20.,  0.],\n","          [0., 21., 22., 23.,  0.],\n","          [0., 24., 25., 26.,  0.],\n","          [0.,  0.,  0.,  0.,  0.]]],\n","\n","\n","        [[[0.,  0.,  0.,  0.,  0.],\n","          [0., 27., 28., 29.,  0.],\n","          [0., 30., 31., 32.,  0.],\n","          [0., 33., 34., 35.,  0.],\n","          [0.,  0.,  0.,  0.,  0.]],\n","\n","         [[0.,  0.,  0.,  0.,  0.],\n","          [0., 36., 37., 38.,  0.],\n","          [0., 39., 40., 41.,  0.],\n","          [0., 42., 43., 44.,  0.],\n","          [0.,  0.,  0.,  0.,  0.]],\n","\n","         [[0.,  0.,  0.,  0.,  0.],\n","          [0., 45., 46., 47.,  0.],\n","          [0., 48., 49., 50.,  0.],\n","          [0., 51., 52., 53.,  0.],\n","          [0.,  0.,  0.,  0.,  0.]]]])\n","\n","# Проверка происходит автоматически вызовом следующего кода\n","# (раскомментируйте для самостоятельной проверки,\n","#  в коде для сдачи задания должно быть закомментировано):\n","# print(torch.allclose(get_padding2d(input_images), correct_padded_images))"],"metadata":{"id":"ytulzZygZZv1","executionInfo":{"status":"ok","timestamp":1679053767950,"user_tz":-180,"elapsed":371,"user":{"displayName":"Матвей Званцов","userId":"01712077817502948720"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["padd = get_padding2d(input_images)\n","padd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"JsDqEX0qZgce","executionInfo":{"status":"error","timestamp":1679053772419,"user_tz":-180,"elapsed":476,"user":{"displayName":"Матвей Званцов","userId":"01712077817502948720"}},"outputId":"241e62f8-ae7d-4e02-ad34-c54e63579bee"},"execution_count":4,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-f98202ce9313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpadd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_padding2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpadd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-314d5e9c0bf9>\u001b[0m in \u001b[0;36mget_padding2d\u001b[0;34m(input_images)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mpadded_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mpadded_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 2 (got 8)"]}]}]}